{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Backpropagation equations with an example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation is probably the most complicated introductory topic when it comes to neural networks. We have to deal with some tedious math and it's easy to loose track of things. We'll approach backpropagation with a *binary* classification example, starting with the derivation of the equations of forward propagation and backpropagation, then we write them in code to verify that everything works. We'll see that with a little patience the basic idea is actually not too complicated. \n",
    "\n",
    "We do not put emphasis on the code itself, we keep it simple and without advanced programming patterns, we focus instead on the concepts that make neural networks work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reach that goal we choose a fully connected, 3-layer, neural network (see figure below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"645.38391\" id=\"svg4169\" inkscape:version=\"0.92.4 (5da689c313, 2019-01-14)\" sodipodi:docname=\"nn3.svg\" version=\"1.1\" width=\"916.00128\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:inkscape=\"http://www.inkscape.org/namespaces/inkscape\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" xmlns:sodipodi=\"http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd\" xmlns:svg=\"http://www.w3.org/2000/svg\">\n",
       "  <metadata id=\"metadata4173\">\n",
       "    <rdf:RDF>\n",
       "      <cc:Work rdf:about=\"\">\n",
       "        <dc:format>image/svg+xml</dc:format>\n",
       "        <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "        <dc:title/>\n",
       "      </cc:Work>\n",
       "    </rdf:RDF>\n",
       "  </metadata>\n",
       "  <sodipodi:namedview bordercolor=\"#666666\" borderopacity=\"1\" fit-margin-bottom=\"50\" fit-margin-left=\"50\" fit-margin-right=\"50\" fit-margin-top=\"0\" gridtolerance=\"10\" guidetolerance=\"10\" id=\"namedview4171\" inkscape:current-layer=\"svg4169\" inkscape:cx=\"323.61732\" inkscape:cy=\"442.57126\" inkscape:pageopacity=\"0\" inkscape:pageshadow=\"2\" inkscape:window-height=\"1387\" inkscape:window-maximized=\"1\" inkscape:window-width=\"1278\" inkscape:window-x=\"1274\" inkscape:window-y=\"-8\" inkscape:zoom=\"0.91385768\" objecttolerance=\"10\" pagecolor=\"#ffffff\" showgrid=\"false\"/>\n",
       "  <g id=\"g4162\" transform=\"matrix(1.4142136,0,0,1.4142136,-564.7115,-629.32505)\">\n",
       "    <path class=\"link\" d=\"m 447.16667,589.5 184,-88\" id=\"path3944\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,589.5 184,-44\" id=\"path3946\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,589.5 h 184\" id=\"path3948\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,589.5 184,44\" id=\"path3950\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,589.5 184,88\" id=\"path3952\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,589.5 184,132\" id=\"path3954\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,589.5 184,176\" id=\"path3956\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,589.5 184,220\" id=\"path3958\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,589.5 184,264\" id=\"path3960\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,633.5 184,-132\" id=\"path3962\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,633.5 184,-88\" id=\"path3964\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,633.5 184,-44\" id=\"path3966\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,633.5 h 184\" id=\"path3968\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,633.5 184,44\" id=\"path3970\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,633.5 184,88\" id=\"path3972\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,633.5 184,132\" id=\"path3974\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,633.5 184,176\" id=\"path3976\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,633.5 184,220\" id=\"path3978\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,677.5 184,-176\" id=\"path3980\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,677.5 184,-132\" id=\"path3982\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,677.5 184,-88\" id=\"path3984\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,677.5 184,-44\" id=\"path3986\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,677.5 h 184\" id=\"path3988\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,677.5 184,44\" id=\"path3990\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,677.5 184,88\" id=\"path3992\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,677.5 184,132\" id=\"path3994\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,677.5 184,176\" id=\"path3996\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,721.5 184,-220\" id=\"path3998\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,721.5 184,-176\" id=\"path4000\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,721.5 184,-132\" id=\"path4002\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,721.5 184,-88\" id=\"path4004\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,721.5 184,-44\" id=\"path4006\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,721.5 h 184\" id=\"path4008\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,721.5 184,44\" id=\"path4010\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,721.5 184,88\" id=\"path4012\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,721.5 184,132\" id=\"path4014\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,457.5 184,154\" id=\"path4016\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,457.5 184,198\" id=\"path4018\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,457.5 184,242\" id=\"path4020\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,501.5 184,110\" id=\"path4022\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,501.5 184,154\" id=\"path4024\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,501.5 184,198\" id=\"path4026\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,545.5 184,66\" id=\"path4028\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,545.5 184,110\" id=\"path4030\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,545.5 184,154\" id=\"path4032\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,589.5 184,22\" id=\"path4034\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,589.5 184,66\" id=\"path4036\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,589.5 184,110\" id=\"path4038\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,633.5 184,-22\" id=\"path4040\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,633.5 184,22\" id=\"path4042\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,633.5 184,66\" id=\"path4044\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,677.5 184,-66\" id=\"path4046\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,677.5 184,-22\" id=\"path4048\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,677.5 184,22\" id=\"path4050\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,721.5 184,-110\" id=\"path4052\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,721.5 184,-66\" id=\"path4054\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,721.5 184,-22\" id=\"path4056\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,765.5 184,-154\" id=\"path4058\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,765.5 184,-110\" id=\"path4060\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,765.5 184,-66\" id=\"path4062\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,809.5 184,-198\" id=\"path4064\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,809.5 184,-154\" id=\"path4066\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,809.5 184,-110\" id=\"path4068\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,853.5 184,-242\" id=\"path4070\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,853.5 184,-198\" id=\"path4072\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,853.5 184,-154\" id=\"path4074\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 815.16667,567.5 184,88\" id=\"path4076\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 815.16667,611.5 184,44\" id=\"path4078\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 815.16667,655.5 h 184\" id=\"path4080\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 815.16667,699.5 184,-44\" id=\"path4082\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,457.5 184,286\" id=\"path4084\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,501.5 184,242\" id=\"path4086\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,545.5 184,198\" id=\"path4088\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,589.5 184,154\" id=\"path4090\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,633.5 184,110\" id=\"path4092\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,677.5 184,66\" id=\"path4094\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,721.5 184,22\" id=\"path4096\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,765.5 184,-22\" id=\"path4098\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,809.5 184,-66\" id=\"path4100\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,853.5 184,-110\" id=\"path4102\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 815.16667,743.5 184,-88\" id=\"path4104\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,589.5 184,-132\" id=\"path4106\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,633.5 184,-176\" id=\"path4108\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,677.5 184,-220\" id=\"path4110\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 447.16667,721.5 184,-264\" id=\"path4112\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,457.5 184,110\" id=\"path4114\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,501.5 184,66\" id=\"path4116\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,545.5 184,22\" id=\"path4118\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,589.5 184,-22\" id=\"path4120\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,633.5 184,-66\" id=\"path4122\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,677.5 184,-110\" id=\"path4124\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,721.5 184,-154\" id=\"path4126\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,765.5 184,-198\" id=\"path4128\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,809.5 184,-242\" id=\"path4130\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <path class=\"link\" d=\"m 631.16667,853.5 184,-286\" id=\"path4132\" inkscape:connector-curvature=\"0\" style=\"stroke:#505050;stroke-width:0.50999999px;stroke-opacity:1;marker-end:url(#arrow)\"/>\n",
       "    <circle class=\"node\" cx=\"447.16666\" cy=\"589.5\" id=\"0_0\" r=\"12\" style=\"fill:#ffffff;stroke:#333333\"/>\n",
       "    <circle class=\"node\" cx=\"447.16666\" cy=\"633.5\" id=\"0_1\" r=\"12\" style=\"fill:#ffffff;stroke:#333333\"/>\n",
       "    <circle class=\"node\" cx=\"447.16666\" cy=\"677.5\" id=\"0_2\" r=\"12\" style=\"fill:#ffffff;stroke:#333333\"/>\n",
       "    <circle class=\"node\" cx=\"447.16666\" cy=\"721.5\" id=\"0_3\" r=\"12\" style=\"fill:#ffffff;stroke:#333333\"/>\n",
       "    <circle class=\"node\" cx=\"631.16669\" cy=\"457.5\" id=\"1_0\" r=\"12\" style=\"fill:#ffffff;stroke:#333333\"/>\n",
       "    <circle class=\"node\" cx=\"631.16669\" cy=\"501.5\" id=\"1_1\" r=\"12\" style=\"fill:#ffffff;stroke:#333333\"/>\n",
       "    <circle class=\"node\" cx=\"631.16669\" cy=\"545.5\" id=\"1_2\" r=\"12\" style=\"fill:#ffffff;stroke:#333333\"/>\n",
       "    <circle class=\"node\" cx=\"631.16669\" cy=\"589.5\" id=\"1_3\" r=\"12\" style=\"fill:#ffffff;stroke:#333333\"/>\n",
       "    <circle class=\"node\" cx=\"631.16669\" cy=\"633.5\" id=\"1_4\" r=\"12\" style=\"fill:#ffffff;stroke:#333333\"/>\n",
       "    <circle class=\"node\" cx=\"631.16669\" cy=\"677.5\" id=\"1_5\" r=\"12\" style=\"fill:#ffffff;stroke:#333333\"/>\n",
       "    <circle class=\"node\" cx=\"631.16669\" cy=\"721.5\" id=\"1_6\" r=\"12\" style=\"fill:#ffffff;stroke:#333333\"/>\n",
       "    <circle class=\"node\" cx=\"631.16669\" cy=\"765.5\" id=\"1_7\" r=\"12\" style=\"fill:#ffffff;stroke:#333333\"/>\n",
       "    <circle class=\"node\" cx=\"631.16669\" cy=\"809.5\" id=\"1_8\" r=\"12\" style=\"fill:#ffffff;stroke:#333333\"/>\n",
       "    <circle class=\"node\" cx=\"631.16669\" cy=\"853.5\" id=\"1_9\" r=\"12\" style=\"fill:#ffffff;stroke:#333333\"/>\n",
       "    <circle class=\"node\" cx=\"815.16669\" cy=\"567.5\" id=\"2_0\" r=\"12\" style=\"fill:#ffffff;stroke:#333333\"/>\n",
       "    <circle class=\"node\" cx=\"815.16669\" cy=\"611.5\" id=\"2_1\" r=\"12\" style=\"fill:#ffffff;stroke:#333333\"/>\n",
       "    <circle class=\"node\" cx=\"815.16669\" cy=\"655.5\" id=\"2_2\" r=\"12\" style=\"fill:#ffffff;stroke:#333333\"/>\n",
       "    <circle class=\"node\" cx=\"815.16669\" cy=\"699.5\" id=\"2_3\" r=\"12\" style=\"fill:#ffffff;stroke:#333333\"/>\n",
       "    <circle class=\"node\" cx=\"815.16669\" cy=\"743.5\" id=\"2_4\" r=\"12\" style=\"fill:#ffffff;stroke:#333333\"/>\n",
       "    <circle class=\"node\" cx=\"999.16669\" cy=\"655.5\" id=\"3_0\" r=\"12\" style=\"fill:#ffffff;stroke:#333333\"/>\n",
       "    <text class=\"text\" dy=\"0.34999999em\" id=\"text4154\" style=\"font-size:12px\" x=\"412.16666\" y=\"897.5\"/>\n",
       "    <text class=\"text\" dy=\"0.34999999em\" id=\"text4156\" style=\"font-size:12px\" x=\"596.16669\" y=\"897.5\"/>\n",
       "    <text class=\"text\" dy=\"0.34999999em\" id=\"text4158\" style=\"font-size:12px\" x=\"780.16669\" y=\"897.5\"/>\n",
       "    <text class=\"text\" dy=\"0.34999999em\" id=\"text4160\" style=\"font-size:12px\" x=\"964.16669\" y=\"897.5\"/>\n",
       "  </g>\n",
       "  <defs id=\"defs4167\">\n",
       "    <marker id=\"arrow\" markerHeight=\"7\" markerWidth=\"7\" orient=\"auto\" refX=\"45.599998\" viewBox=\"0 -5 10 10\">\n",
       "      <path d=\"M 0,-5 10,0 0,5\" id=\"path4164\" inkscape:connector-curvature=\"0\" style=\"fill:#505050;stroke:#505050\"/>\n",
       "    </marker>\n",
       "  </defs>\n",
       "  <text id=\"text130\" style=\"font-style:normal;font-weight:normal;font-size:24px;line-height:1.25;font-family:'Cambria Math';letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;-inkscape-font-specification:'Cambria Math';font-stretch:normal;font-variant:normal;\" x=\"260.43442\" xml:space=\"preserve\" y=\"622.40442\"><tspan id=\"tspan128\" sodipodi:role=\"line\" style=\"-inkscape-font-specification:'Cambria Math';font-family:'Cambria Math';font-weight:normal;font-style:normal;font-stretch:normal;font-variant:normal;\" x=\"260.43442\" y=\"622.40442\">hidden layer 1</tspan></text>\n",
       "  <text id=\"text134\" style=\"font-style:normal;font-weight:normal;font-size:24px;line-height:1.25;font-family:'Cambria Math';letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;-inkscape-font-specification:'Cambria Math';font-stretch:normal;font-variant:normal;\" x=\"526.34015\" xml:space=\"preserve\" y=\"476.86752\"><tspan id=\"tspan132\" sodipodi:role=\"line\" style=\"font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-family:'Cambria Math';-inkscape-font-specification:'Cambria Math';\" x=\"526.34015\" y=\"476.86752\">hidden layer 2</tspan></text>\n",
       "  <text id=\"text138\" style=\"font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:24px;line-height:1.25;font-family:'Cambria Math';-inkscape-font-specification:'Cambria Math';letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none\" x=\"756.13525\" xml:space=\"preserve\" y=\"372.9126\"><tspan id=\"tspan136\" sodipodi:role=\"line\" style=\"font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-family:'Cambria Math';-inkscape-font-specification:'Cambria Math'\" x=\"756.13525\" y=\"372.9126\">output layer</tspan></text>\n",
       "  <text id=\"text142\" style=\"font-style:normal;font-weight:normal;font-size:24px;line-height:1.25;font-family:'Cambria Math';letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;-inkscape-font-specification:'Cambria Math';font-stretch:normal;font-variant:normal;\" x=\"96.295082\" xml:space=\"preserve\" y=\"81.838829\"><tspan id=\"tspan140\" sodipodi:role=\"line\" style=\"-inkscape-font-specification:'Cambria Math';font-family:'Cambria Math';font-weight:normal;font-style:normal;font-stretch:normal;font-variant:normal;\" x=\"96.295082\" y=\"81.838829\">W</tspan></text>\n",
       "  <text id=\"text146\" style=\"font-style:normal;font-weight:normal;font-size:24px;line-height:1.25;font-family:'Cambria Math';letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;-inkscape-font-specification:'Cambria Math';font-stretch:normal;font-variant:normal;\" x=\"121.46312\" xml:space=\"preserve\" y=\"61.047848\"><tspan id=\"tspan144\" sodipodi:role=\"line\" style=\"-inkscape-font-specification:'Cambria Math';font-family:'Cambria Math';font-weight:normal;font-style:normal;font-stretch:normal;font-variant:normal;\" x=\"121.46312\" y=\"61.047848\">(1)</tspan></text>\n",
       "  <text id=\"text150\" style=\"font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:24px;line-height:1.25;font-family:'Cambria Math';-inkscape-font-specification:'Cambria Math';letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none\" x=\"99.954918\" xml:space=\"preserve\" y=\"123.4208\"><tspan id=\"tspan148\" sodipodi:role=\"line\" style=\"font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-family:'Cambria Math';-inkscape-font-specification:'Cambria Math'\" x=\"99.954918\" y=\"123.4208\">a</tspan></text>\n",
       "  <text id=\"text154\" style=\"font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:24px;line-height:1.25;font-family:'Cambria Math';-inkscape-font-specification:'Cambria Math';letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none\" x=\"113.46312\" xml:space=\"preserve\" y=\"110.10112\"><tspan id=\"tspan152\" sodipodi:role=\"line\" style=\"font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-family:'Cambria Math';-inkscape-font-specification:'Cambria Math'\" x=\"113.46312\" y=\"110.10112\">(1)</tspan></text>\n",
       "  <text id=\"text142-9\" style=\"font-style:normal;font-weight:normal;font-size:24px;line-height:1.25;font-family:'Cambria Math';letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;-inkscape-font-specification:'Cambria Math';font-stretch:normal;font-variant:normal;\" x=\"459.07999\" xml:space=\"preserve\" y=\"52.493633\"><tspan id=\"tspan140-0\" sodipodi:role=\"line\" style=\"font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-family:'Cambria Math';-inkscape-font-specification:'Cambria Math';\" x=\"459.07999\" y=\"52.493633\">W</tspan></text>\n",
       "  <text id=\"text146-1\" style=\"font-style:normal;font-weight:normal;font-size:24px;line-height:1.25;font-family:'Cambria Math';letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;-inkscape-font-specification:'Cambria Math';font-stretch:normal;font-variant:normal;\" x=\"482.24805\" xml:space=\"preserve\" y=\"31.702652\"><tspan id=\"tspan144-1\" sodipodi:role=\"line\" style=\"-inkscape-font-specification:'Cambria Math';font-family:'Cambria Math';font-weight:normal;font-style:normal;font-stretch:normal;font-variant:normal;\" x=\"482.24805\" y=\"31.702652\">(2)</tspan></text>\n",
       "  <text id=\"text150-6\" style=\"font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:24px;line-height:1.25;font-family:'Cambria Math';-inkscape-font-specification:'Cambria Math';letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none\" x=\"462.73984\" xml:space=\"preserve\" y=\"96.075607\"><tspan id=\"tspan148-8\" sodipodi:role=\"line\" style=\"font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-family:'Cambria Math';-inkscape-font-specification:'Cambria Math'\" x=\"462.73984\" y=\"96.075607\">a</tspan></text>\n",
       "  <text id=\"text154-2\" style=\"font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:24px;line-height:1.25;font-family:'Cambria Math';-inkscape-font-specification:'Cambria Math';letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none\" x=\"476.24805\" xml:space=\"preserve\" y=\"80.75592\"><tspan id=\"tspan152-5\" sodipodi:role=\"line\" style=\"font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-family:'Cambria Math';-inkscape-font-specification:'Cambria Math'\" x=\"476.24805\" y=\"80.75592\">(2)</tspan></text>\n",
       "  <text id=\"text142-8\" style=\"font-style:normal;font-weight:normal;font-size:24px;line-height:1.25;font-family:'Cambria Math';letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;-inkscape-font-specification:'Cambria Math';font-stretch:normal;font-variant:normal;\" x=\"709.66608\" xml:space=\"preserve\" y=\"151.50594\"><tspan id=\"tspan140-8\" sodipodi:role=\"line\" style=\"-inkscape-font-specification:'Cambria Math';font-family:'Cambria Math';font-weight:normal;font-style:normal;font-stretch:normal;font-variant:normal;\" x=\"709.66608\" y=\"151.50594\">W</tspan></text>\n",
       "  <text id=\"text146-2\" style=\"font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:24px;line-height:1.25;font-family:'Cambria Math';-inkscape-font-specification:'Cambria Math';letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none\" x=\"730.83411\" xml:space=\"preserve\" y=\"130.71495\"><tspan id=\"tspan144-3\" sodipodi:role=\"line\" x=\"730.83411\" y=\"130.71495\">(3)</tspan></text>\n",
       "  <text id=\"text150-4\" style=\"font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:24px;line-height:1.25;font-family:'Cambria Math';-inkscape-font-specification:'Cambria Math';letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none\" x=\"715.32593\" xml:space=\"preserve\" y=\"197.08791\"><tspan id=\"tspan148-9\" sodipodi:role=\"line\" style=\"font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-family:'Cambria Math';-inkscape-font-specification:'Cambria Math'\" x=\"715.32593\" y=\"197.08791\">a</tspan></text>\n",
       "  <text id=\"text154-8\" style=\"font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:24px;line-height:1.25;font-family:'Cambria Math';-inkscape-font-specification:'Cambria Math';letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none\" x=\"726.83411\" xml:space=\"preserve\" y=\"183.76822\"><tspan id=\"tspan152-2\" sodipodi:role=\"line\" x=\"726.83411\" y=\"183.76822\">(3)</tspan></text>\n",
       "  <text id=\"text242\" style=\"font-style:normal;font-weight:normal;font-size:24px;line-height:1.25;font-family:'Cambria Math';letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;-inkscape-font-specification:'Cambria Math';font-stretch:normal;font-variant:normal;\" x=\"27.35656\" xml:space=\"preserve\" y=\"464.83066\"><tspan id=\"tspan240\" sodipodi:role=\"line\" style=\"font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-family:'Cambria Math';-inkscape-font-specification:'Cambria Math';\" x=\"27.35656\" y=\"464.83066\">Input layer</tspan></text>\n",
       "  <text id=\"text246\" style=\"font-style:normal;font-weight:normal;font-size:24px;line-height:1.25;font-family:'Cambria Math';letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;-inkscape-font-specification:'Cambria Math';font-stretch:normal;font-variant:normal;\" x=\"33.922131\" xml:space=\"preserve\" y=\"519.54376\"><tspan id=\"tspan244\" sodipodi:role=\"line\" x=\"33.922131\" y=\"519.54376\">a</tspan></text>\n",
       "  <text id=\"text250\" style=\"font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:24px;line-height:1.25;font-family:'Cambria Math';-inkscape-font-specification:'Cambria Math';letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none\" x=\"41.959015\" xml:space=\"preserve\" y=\"503.84702\"><tspan id=\"tspan248\" sodipodi:role=\"line\" x=\"41.959015\" y=\"503.84702\">(0)</tspan></text>\n",
       "  <text id=\"text254\" style=\"font-style:normal;font-weight:normal;font-size:24px;line-height:1.25;font-family:'Cambria Math';letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;-inkscape-font-specification:'Cambria Math';font-stretch:normal;font-variant:normal;\" x=\"74.409836\" xml:space=\"preserve\" y=\"521.7323\"><tspan id=\"tspan252\" sodipodi:role=\"line\" x=\"74.409836\" y=\"521.7323\"> = x</tspan></text>\n",
       "  <flowRoot id=\"flowRoot256\" style=\"fill:black;fill-opacity:1;stroke:none;font-family:sans-serif;font-style:normal;font-weight:normal;font-size:24px;line-height:1.25;letter-spacing:0px;word-spacing:0px\" xml:space=\"preserve\"><flowRegion id=\"flowRegion258\"><rect height=\"102.86066\" id=\"rect260\" width=\"148.81967\" x=\"670.78278\" y=\"114.6667\"/></flowRegion><flowPara id=\"flowPara262\"/></flowRoot></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "\n",
    "SVG('nn3.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define the notation:\n",
    "- $n^{l}$ is the number of neurons in layer $l$ \n",
    "- $W^{(l)}$ is the weights matrix from layer $l-1$ to layer $l$. It has dimensions ($n^{(l)} \\times n^{(l-1)}$)\n",
    "- $b^{(l)}$ (not displayed above) is the vector of biases of layer $l$. It has dimensions $n^{(l)} \\times 1$\n",
    "- $a^{(l)}$ is the vector of activations, that is, the output of the layer $l$. It has dimensions  $n^{(l)} \\times 1$\n",
    "- $z^{(l)}$ is the vector of pre-activations. We have $a^{(l)} = f^{(l)}(z^{(l)})$ where $f^{(l)}$ is the *activation function* of layer $l$.\n",
    "- we indicate with $x$ the input sample and with $y$ the target variable. $\\hat{y}$ is the predicted output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights and the biases are the parameters of the network we need to optimize for in order to minimize the output error. At that point the neural network starts to look like a viable model for the dataset that we are studying. It's not all there is to do to have a \"good\" model (consider for example overfitting) but it's a necessary and fundamental step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The three steps of neural network operation\n",
    "\n",
    "We can divide the operation of neural networks in 3 main steps:\n",
    "- Foward Propagation, where the output of the network is calculated starting from the input\n",
    "- Loss/cost function calculation, where the distance of the calculated output from the \"true\" target variable is calculated\n",
    "- Backpropagation and parameters update, *this is the part we focus on in this notebook*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the neural network doing. Logistic Regression.\n",
    "A few words are needed to clarify what is the neuwal network's task. In essence the neural network paradigm is a way to calculate numerically a probability distribution. I want to underline this point of view because calcating probability distributions and comparing their distance are ubiquitous concepts in Machine Learning. Nothing to worry about, let's refer to the binary case to fix some ideas. \n",
    "\n",
    "In a binary classification task the samples belong either to class 1 or 0 (or to classes \"a\" and \"b\"). If we denote with $y$ the class variable, we have that for each sample $y=1$ or $y=0$. We interpret the target variable $y$ as being a [Bernoulli](https://en.wikipedia.org/wiki/Bernoulli_distribution) distriuted variable and each sample belongs to one class or the other with probability $p$ or $1 - p$ respectively. In other words, we interpret the ones and zeros as 100% and 0% probability of belonging to one or the other class. If the first sample belongs to class \"a\" we can associate a \"1\" to it to indicate that it belongs to class \"a\" with 100% probability. The second sample perhaps belongs to class \"b\", we then associate to it a value of \"0\" that is, it belongs to class \"a\" with $1 - 1 = 0$ (0%) probability. \n",
    "\n",
    "The output of the network $\\hat{y}$ should also be interpreted as a probability of a Bernoulli distributed variable that tells us if each sample belongs to one class with probability $q$ and to the other with probability $1 - q$. Now that we have two probability distributions we can calculate their *distance*, that is, the distance between the ground truth and the network calculated \"truth\". The last step would then be to minimize such distance. \n",
    "\n",
    "How do we make the network calculate a Bernoulli distributed variable $\\hat{y}$? We apply a [sigmoid](https://en.wikipedia.org/wiki/Sigmoid_function) function at its output forcing the network to output a number between 0 and 1 *that we can interpret as a probability*. It's the same idea that is behind [logistic regression](https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_loss_function_and_logistic_regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward propagation in a fully connected network is straightforward. The output is calculated by a sequence of matrix multiplications. If we indicate the input to the neural network with $x$ (also equal to $a^{(0)})$ we have that the output of layer 1 is $$a^{(1)} = f^{(1)}(z^{(1)})$$\n",
    "with $$z^{(1)}=w^{(1)} \\cdot a^{(0)} + b^{(1)}.$$\n",
    "\n",
    "For the generic layer l we have:\n",
    "$$a^{(l)} = f^{(l)}(z^{(l)})$$\n",
    "$$z^{(l)} = w^{(l)} \\cdot a^{(l-1)} + b^{(l)}$$\n",
    "where the dot \"$\\cdot$\" is the row-column matrix multiplication. In our case we have l=1, 2, 3 so we need to repeat the previous equations 3 times. For an arbitrary number of layers we just need to put those two equations in a loop, and loop over the number of layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification. Loss function.\n",
    "\n",
    "After the network has made its prediction during forward propagaion (calculating $\\hat{y}$) we can compare the \"true\" probability distribution to the network calculated distribution.\n",
    "Initially the weights in the matrices $W^{(l)}$ and the biases in the vectors $b^{(l)}$ are initialized randomly so the network won't give us a prediction that is close to the ground truth. To quantify that distance (and to minimize it) we need to comput the loss function. In our case we choose the [cross-entropy](https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_loss_function_and_logistic_regression) which is defned as follows for two probability distributions $p$ and $q$:\n",
    "$$H(p,q) = \\sum^C_ip_i\\log(q_i),$$\n",
    "where $C$ is the number of classes. Why the cross entropy? \n",
    "For the binary classification problem the formula reduces to: \n",
    "$$\\mathcal{L} = - (y \\log(\\hat{y}) + (1 - y) \\log(1-\\hat{y})).$$ \n",
    "We feed one sample with one sample at a time, calculate the update of the weights and biases and apply the update for each sample, that is we choose the *on line* gradient descent training. It is probably the simplest way to train a network so it doesn't clutter us with more code. In the *batch* training version instead, we calculate the update of the weights and biases for each sample but we apply it only when all the samples in the batch have been presented to the network. Batch training is out of the scope of this article but the reader can see for example [here](http://axon.cs.byu.edu/papers/Wilson.nn03.batch.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "\n",
    "We now discuss the real reson why we are here, that is, the equations of *backpropagation*. The goal of backpropagation is to minimize the loss function by calculating by how much we need to change the weights and biases of the network. In the amount by which we need to change the parameters of the network is given by the equations of *gradient descent*:\n",
    "$$w^{(l)} = w^{(l)} - \\alpha \\frac{\\partial \\mathcal{L}}{\\partial w^{(l)}}$$\n",
    "$$b^{(l)} = w^{(l)} - \\alpha \\frac{\\partial \\mathcal{l}}{\\partial b^{(l)}}$$\n",
    "where the weight $\\alpha$ is a scalar number that controls the *learning rate*, that is, how big of a step we let the gradient descent make at each minimization iteration.\n",
    "All we need to do then is to calculate the partial derivatives in the formulae above. That is readily done by applying the chain rule starting from the output which gives us the following:\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial w^{(3)}} = \\frac{\\partial C}{\\partial a^{(3)}}\\frac{\\partial a^{(3)}}{\\partial z^{(3)}}\\frac{\\partial z^{(3)}}{\\partial w^{(3)}} $$, and a similar equation applies for the biases $b^{(3)}$.\n",
    "At this point we can update the weights of the last layer but we need to calculate the update for the previous layers as well. Going back to the second last layer we have:\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial w^{(2)}} = \\frac{\\partial C}{\\partial a^{(3)}}\\frac{\\partial a^{(3)}}{\\partial z^{(3)}} \\frac{\\partial z^{(3)}}{\\partial a^{(2)}} \\frac{\\partial a^{(2)}}{\\partial z^{(2)}} \\frac{\\partial z^{(2)}}{\\partial w^{(2)}}$$\n",
    "**to be continued**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(vec):\n",
    "    \"\"\" Sigmoid activation function\n",
    "\n",
    "    Args:\n",
    "        vec: input features vector\n",
    "    \"\"\"\n",
    "    return 1/(1 + np.exp(-vec))\n",
    "\n",
    "\n",
    "def diff_sigmoid(vec):\n",
    "    \"\"\" derivative of the sigmoid \n",
    "    \n",
    "    Args:\n",
    "        vec: vector with respect to differentiate for\n",
    "    \"\"\"\n",
    "    return sigmoid(vec) * (1. - sigmoid(vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network(object):\n",
    "    def __init__(self, n_features, alpha=0.01):\n",
    "        \"\"\" Initalize weights and biases of the neural net\n",
    "            \n",
    "            Args:\n",
    "                n_features: number of features in the input matrix\n",
    "                alpha: learning rate\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.W1 = np.random.normal(0, .1, (10, n_features))\n",
    "        self.W2 = np.random.normal(0, .1, (5, 10))\n",
    "        self.W3 = np.random.normal(0, .1, (1, 5)) \n",
    "        \n",
    "        self.b1 = np.ones((10, 1))\n",
    "        self.b2 = np.ones((5, 1))\n",
    "        self.b3 = np.ones((1, 1))\n",
    "\n",
    "        # \"memory\" of the network\n",
    "        # we keep intermediate results needed for the backpropagation\n",
    "\n",
    "        self.z1 = None\n",
    "        self.a1 = None\n",
    "        self.z2 = None\n",
    "        self.a2 = None\n",
    "        self.z3 = None\n",
    "        self.a3 = None        \n",
    "\n",
    "    @staticmethod\n",
    "    def cross_entropy_loss(y_hat, y):\n",
    "        \"\"\" calculates the loss function \n",
    "        \n",
    "            Args:\n",
    "                y_hat: calculated output array\n",
    "                y:     ground truth array      \n",
    "        \"\"\"\n",
    "        y_hat = np.squeeze(y_hat)\n",
    "        loss = y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat)\n",
    "        return - loss\n",
    "\n",
    "    def forward_prop(self, x):\n",
    "        \"\"\" Calculates the output of the neural net\n",
    "\n",
    "        Args:\n",
    "            x: input features vector\n",
    "        \"\"\"\n",
    "        self.x = x\n",
    "        self.z1 = np.dot(self.W1, x) + self.b1\n",
    "        self.a1 = sigmoid(self.z1)\n",
    "\n",
    "        self.z2 = np.dot(self.W2, self.a1) + self.b2\n",
    "        self.a2 = sigmoid(self.z2)\n",
    "\n",
    "        self.z3 = np.dot(self.W3, self.a2) + self.b3\n",
    "        self.a3 = sigmoid(self.z3)  # output of the network\n",
    "\n",
    "        return self.a3\n",
    "    \n",
    "    def backprop(self, y_hat, y):\n",
    "        \"\"\" backpropagation \n",
    "            \n",
    "            Args:\n",
    "                y_hat: array with the prediction (forward propagation)\n",
    "                y: classes (ground truth)\n",
    "        \"\"\"\n",
    "        self.dCdz3 = y_hat - y\n",
    "        self.dCdW3 = np.dot(self.dCdz3, self.a2.T)\n",
    "        self.dCdb3 = self.dCdz3\n",
    "\n",
    "        self.dCdz2 = np.dot(self.W3.T, self.dCdz3) * diff_sigmoid(self.z2)\n",
    "        self.dCdW2 = np.dot(self.dCdz2, self.a1.T)\n",
    "        self.dCdb2 = self.dCdz2\n",
    "\n",
    "        self.dCdz1 = np.dot(self.W2.T, self.dCdz2) * diff_sigmoid(self.z1)\n",
    "        self.dCdW1 = np.dot(self.dCdz1, self.x.T)\n",
    "        self.dCdb1 = self.dCdz1        \n",
    "\n",
    "        self.update()\n",
    "\n",
    "    def update(self):\n",
    "        \"\"\" update the weights and biases \"\"\"\n",
    "        self.W1 = self.W1 - self.alpha * np.squeeze(self.dCdW1)\n",
    "        self.W2 = self.W2 - self.alpha * self.dCdW2\n",
    "        self.W3 = self.W3 - self.alpha * self.dCdW3\n",
    "\n",
    "        self.b1 = self.b1 - self.alpha * self.dCdb1\n",
    "        self.b2 = self.b2 - self.alpha * self.dCdb2\n",
    "        self.b3 = self.b3 - self.alpha * self.dCdb3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, loss = 1.353666696377922\n",
      "average test set accuracy = 0.5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Singleton array 1 cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-ae9a30a0e5ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# average number of correct prediction per epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"average test set accuracy = {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maverage_correct\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fraction of correctly classified = {}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margmin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \"\"\"\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \"\"\"\n\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \"\"\"\n\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             raise TypeError(\"Singleton array %r cannot be considered\"\n\u001b[1;32m--> 119\u001b[1;33m                             \" a valid collection.\" % x)\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Singleton array 1 cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "    iris = datasets.load_iris()\n",
    "    df = np.c_[iris.data, iris.target]\n",
    "    df = df[:100, :]  # binary classification, only 2 classes\n",
    "\n",
    "    np.random.shuffle(df)\n",
    "\n",
    "    X = df[:, :-1]\n",
    "    y = df[:, -1]\n",
    "\n",
    "    minmax = MinMaxScaler()\n",
    "    minmax_x = minmax.fit(X)    \n",
    "    minmax_y = minmax.fit(y.reshape(-1, 1)) \n",
    "\n",
    "    X = minmax_x.transform(X)    \n",
    "    y = minmax_y.transform(y.reshape(-1, 1))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "    the_net = network(alpha=0.25, n_features=X_train.shape[1])\n",
    "\n",
    "    y_values = np.unique(y_train)\n",
    "\n",
    "    epoch_loss = []    \n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    average_correct = []\n",
    "    predicted_train_classes = []\n",
    "    predicted_test_classes = []\n",
    "    for epoch in range(0, 100):\n",
    "        # train and update one sample at a time, \"on line\" SGD. Go through all the samples\n",
    "        for sample in range(X_train.shape[0]):\n",
    "            x = np.expand_dims(X_train[sample, :], axis=1)\n",
    "            # 1. forward pass\n",
    "            y_hat = the_net.forward_prop(x)     \n",
    "            # 2. compute the loss\n",
    "            loss = the_net.cross_entropy_loss(y_hat, y_train[sample])   \n",
    "            # 3. backpropagate and update weights and biases\n",
    "            the_net.backprop(y_hat, y_train[sample])                    \n",
    "\n",
    "        # calculate training set accuracy at the end of every epoch        \n",
    "        for i in range(X_train.shape[0]):\n",
    "            pred = the_net.forward_prop(np.expand_dims(X_train[i, :], axis=1))\n",
    "            argmin = np.argmin(np.abs(pred - y_values))\n",
    "            predicted_train_classes.append(y_values[argmin])\n",
    "            # correct prediction of the training set samples\n",
    "            # train_acc.append((predicted_train_classes[-1] == y_train[i])[0])\n",
    "        \n",
    "        epoch_loss.append(loss)\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Epoch = {}\".format(epoch))\n",
    "            print(\"Average Epoch Loss = {}\".format(np.mean(epoch_loss)))\n",
    "            print(\"Training set accuracy score = {:1.3f}\\n\".format(accuracy_score(y_train, predicted_train_classes)))\n",
    "            \n",
    "        predicted_train_classes = []\n",
    "        epoch_loss = []\n",
    "\n",
    "        # train_acc = []\n",
    "\n",
    "    # After the network is trained calculate test set accuracy        \n",
    "    for i in range(X_test.shape[0]):\n",
    "        pred = the_net.forward_prop(np.expand_dims(X_test[i, :], axis=1))\n",
    "        argmin = np.argmin(np.abs(pred - y_values))\n",
    "        predicted_test_classes.append(y_values[argmin])       \n",
    "\n",
    "    print(\"Test set accuracy score = {:1.3f}\".format(accuracy_score(y_test, predicted_test_classes)))\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(14,6))\n",
    "\n",
    "ax[0].plot(epoch_loss, marker=\".\", lw=2)\n",
    "ax[0].set_xlabel(\"epoch\", fontsize=16)\n",
    "ax[0].set_ylabel(\"loss\", fontsize=16)\n",
    "ax[0].set_xticklabels(ax[0].get_xticks().astype(int), fontsize=18)\n",
    "ax[0].set_yticklabels(np.around(ax[0].get_yticks(), decimals=1), fontsize=18)\n",
    "\n",
    "ax[1].plot(average_correct, marker=\".\", lw=2)\n",
    "ax[1].set_xlabel(\"epoch\", fontsize=16)\n",
    "ax[1].set_ylabel(\"train set accuracy\", fontsize=16)\n",
    "ax[1].set_xticklabels(ax[1].get_xticks().astype(int), fontsize=18)\n",
    "ax[1].set_yticklabels(np.around(ax[1].get_yticks(), decimals=1), fontsize=18)\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extras\n",
    "\n",
    "Let's run some classification metics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need some predictions, then we can make the comparison with the ground truh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'roc_curve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-83ee0ce7e14c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'roc_curve' is not defined"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y, scores, pos_label=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.2 64-bit",
   "language": "python",
   "name": "python36264bitec4441131f6b473bac97b47a7653e3c3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
