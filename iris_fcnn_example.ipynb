{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Iris dataset classification with Torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-class classification of the iris dataset with a fully connected net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class fcnn(nn.Module):\n",
    "    def __init__(self, input_features=4, hidden_size=5, output_classes=3):\n",
    "        \"\"\" iris dataset has 4 features and 3 flower species (classes) \"\"\"\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_features, hidden_size)\n",
    "        self.layer2 = nn.Linear(hidden_size, output_classes)       \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.layer1(x))\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "df = np.c_[iris.data, iris.target]\n",
    "\n",
    "np.random.shuffle(df)\n",
    "\n",
    "X = df[:, :-1]\n",
    "y = df[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "y_test = torch.from_numpy(y_test).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we make an instance of the network using the class *fcnn* above then we define the optimizer. We use the [stochastic gradient descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent). The third fundamental ingredient is defining the loss function. We use [cross entropy](https://pytorch.org/docs/master/nn.html#torch.nn.CrossEntropyLoss). Different python packages have slightly different definitions of cross-entropy but Torch's documentation tells us that:\n",
    "1. this function is suited for multi class classification problems.\n",
    "2. We don't have to use the `torch.sigmoid` activation at the output because `CrossEntropyLoss()` already performs the sigmoid. \n",
    "3. We don't need to one-hot encode the classes (target vector `y`) but the target vector should be consist of the class indices (in our case 0, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# instantiate the network\n",
    "net = fcnn()\n",
    "net = net.float()\n",
    "# print(net)\n",
    "\n",
    "# define the optimizer \n",
    "optimizer = optim.SGD(net.parameters(), lr=0.2)    \n",
    "# define the loss\n",
    "loss_fun = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we program a loop to train the network with batch training, that is we take a batch of 20 samples at a time and predict their classes and calculate the network parameter updates with *loss.backward()*. At this point we do not update the parameters of the network, but just calculate the gradients that are necessary for the update. We keep accumulating (adding up) the updates until the end of the outer loop, that is, until the end of the epoch and only then we perform the weights/biases update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, average loss = 0.0010770841035991907\n",
      "Epoch 100, average loss = 0.00020548349129967391\n",
      "Epoch 200, average loss = 0.0001368635130347684\n",
      "Epoch 300, average loss = 0.0001001921045826748\n",
      "Epoch 400, average loss = 9.206093091052026e-05\n",
      "Epoch 500, average loss = 9.066337952390313e-05\n",
      "Epoch 600, average loss = 9.018040145747364e-05\n",
      "Epoch 700, average loss = 9.013263479573652e-05\n",
      "Epoch 800, average loss = 9.02847750694491e-05\n",
      "Epoch 900, average loss = 9.048387437360361e-05\n",
      "test set accuracy 1.0\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "batch_size = 20\n",
    "epoch_loss = []\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()        \n",
    "    for i in range(0, X_train.shape[0], batch_size):\n",
    "\n",
    "        x_b = X_train[i: i + batch_size].float()\n",
    "        y_b = y_train[i: i + batch_size]\n",
    "\n",
    "        y_hat = net(x_b)\n",
    "        loss = loss_fun(y_hat, y_b) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss.append(loss)\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch {}, average loss = {}\".format(epoch, loss/epochs))\n",
    "\n",
    "# test accuracy\n",
    "predicted = net(X_test)\n",
    "_, y_pred = torch.max(predicted, 1)  # output 1 = max, output 2 = argmax\n",
    "\n",
    "print('test set accuracy', accuracy_score(y_test.data, y_pred.data))\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.2 64-bit",
   "language": "python",
   "name": "python36264bitec4441131f6b473bac97b47a7653e3c3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
